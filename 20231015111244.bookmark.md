# kafka | helm-charts (ricardo-aires.github.io)

<https://ricardo-aires.github.io/helm-charts/charts/kafka/>

## Description

Collection of basic helm charts to be used in labs.

## Content

# [helm-charts](https://ricardo-aires.github.io/helm-charts/)

# kafka

A Helm chart for Confluent Kafka on Kubernetes

## Introduction

This chart bootstraps a [Kafka Cluster](https://kafka.apache.org) using the [Confluent](https://docs.confluent.io/home/kafka-intro.html) stable version.

[Kafka](https://kafka.apache.org) is an open-source distributed event streaming platform that:

-   Publishes and subscribes to streams of records, similar to a message queue or enterprise messaging system.
-   Stores streams of records in a fault-tolerant durable way.
-   Processes streams of records as they occur.

## Developing Environment

  component                                                                        version
  -------------------------------------------------------------------------------- ---------
  [Podman](https://docs.podman.io/en/latest/)                                      v4.3.1
  [Minikube](https://minikube.sigs.k8s.io/docs/)                                   v1.28.0
  [Kubernetes](https://kubernetes.io)                                              v1.25.3
  [Helm](https://helm.sh)                                                          v3.10.2
  [Confluent Platform](https://docs.confluent.io/platform/current/overview.html)   v7.3.0

## Installing the Chart

Add the [chart repository](https://helm.sh/docs/helm/helm_repo_add/), if not done before:

``` command
helm repo add rhcharts https://ricardo-aires.github.io/helm-charts/
```

To [install](https://helm.sh/docs/helm/helm_install/) the chart with the release name `kafka`{.language-plaintext .highlighter-rouge}:

``` highlight
$ helm upgrade --install kafka rhcharts/kafka
Release "kafka" does not exist. Installing it now.
NAME: kafka
LAST DEPLOYED: Tue Nov 22 10:30:47 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
** Please be patient while the kafka chart is being deployed in release kafka **

This chart bootstraps a Kafka Cluster made of "3" brokers using the Confluent stable version that can be accessed from within your cluster:

    kafka-headless.default:9092

More info:
https://ricardo-aires.github.io/helm-charts/charts/kafka/
$
```

By default, it will also install the [zookeeper](https://github.com/ricardo-aires/helm-charts/tree/main/charts/zookeeper).

> If an external Zookeeper Ensemble is to be used turn `zookeeper.enabled`{.language-plaintext .highlighter-rouge} to `false`{.language-plaintext .highlighter-rouge} and include the `zookeeper.url`{.language-plaintext .highlighter-rouge}.

These commands deploy Kafka on the Kubernetes cluster in the default configuration. The [Parameters](#parameters) section lists the parameters that can be configured during installation.

The chart will create the next resources, by default:

![Kafka](/helm-charts/charts/kafka/img/kafka.png)

1.  A [PodDisruptionBudget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/) to ensure service availability during planned maintenance.
2.  A [Headless Service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) to control the internal listener for the Kafka.
3.  A [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) which contains 3 Kafka Brokers [Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/), by default.

One can run the:

-   [helm list](https://helm.sh/docs/helm/helm_list/) command to list releases installed
-   [helm status](https://helm.sh/docs/helm/helm_status/) to display the status of the named release
-   [helm test](https://helm.sh/docs/helm/helm_test/) to run tests for a release

To [uninstall](https://helm.sh/docs/helm/helm_uninstall/) the `kafka`{.language-plaintext .highlighter-rouge} deployment run:

``` highlight
helm uninstall kafka
```

The command removes all the Kubernetes components associated with the chart and deletes the release.

> Keep in mind that the [PersistentVolumeClaims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) are in retain.

## Parameters

You can specify each parameter using the `--set key=value[,key=value]`{.language-plaintext .highlighter-rouge} argument to `helm install`{.language-plaintext .highlighter-rouge}.

Alternatively, a YAML file that specifies the values for the parameters can be provided while installing the chart. For example,

``` highlight
helm upgrade --install kafka -f my-values.yaml rhcharts/kafka
```

A default [values.yaml](/helm-charts/charts/kafka/values.yaml) is available and should be checked for more advanced usage.

### Image

By default the [confluentinc/cp-kafka](https://hub.docker.com/r/confluentinc/cp-kafka) is in use.

  Parameter                                                    Description                                     Default
  ------------------------------------------------------------ ----------------------------------------------- -----------------------------------------------------------------
  `image.registry`{.language-plaintext .highlighter-rouge}     Registry used to distribute the Docker Image.   `docker.io`{.language-plaintext .highlighter-rouge}
  `image.repository`{.language-plaintext .highlighter-rouge}   Docker Image of Confluent Kafka.                `confluentinc/cp-kafka`{.language-plaintext .highlighter-rouge}
  `image.tag`{.language-plaintext .highlighter-rouge}          Docker Image Tag of Confluent Kafka.            `7.3.0`{.language-plaintext .highlighter-rouge}

One can easily change the `image.tag`{.language-plaintext .highlighter-rouge} to use another version. When using a local/proxy docker registry we must change `image.registry`{.language-plaintext .highlighter-rouge} as well.

### Kafka Cluster

The configuration parameters in this section control the resources requested and utilized by the kafka chart.

  Parameter                                                Description                    Default
  -------------------------------------------------------- ------------------------------ ---------------------------------------------
  `replicaCount`{.language-plaintext .highlighter-rouge}   The number of Kafka Brokers.   `3`{.language-plaintext .highlighter-rouge}

> The value for the [PodDisruptionBudget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/) is always `maxUnavailable`{.language-plaintext .highlighter-rouge} equals to `1`{.language-plaintext .highlighter-rouge}.

### Confluent Kafka Broker Configuration

The next configuration related to Kafka Broker are available:

  Parameter                                                                 Description                                                                                                                                       Default
  ------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------------------------------------------- ------------------------------------------------------
  `autoCreateTopicsEnable`{.language-plaintext .highlighter-rouge}          Enable auto creation of topic on the server.                                                                                                      `false`{.language-plaintext .highlighter-rouge}
  `deleteTopicEnable`{.language-plaintext .highlighter-rouge}               Delete topic through the admin tool will have no effect if this config is turned off.                                                             `true`{.language-plaintext .highlighter-rouge}
  `offsetsTopicReplicationFactor`{.language-plaintext .highlighter-rouge}   The replication factor for the offsets topic.                                                                                                     `3`{.language-plaintext .highlighter-rouge}
  `numPartitions`{.language-plaintext .highlighter-rouge}                   The default number of log partitions per topic.                                                                                                   `3`{.language-plaintext .highlighter-rouge}
  `defaultReplicationFactor`{.language-plaintext .highlighter-rouge}        The default replication factors for automatically created topics.                                                                                 `3`{.language-plaintext .highlighter-rouge}
  `minInsyncReplicas`{.language-plaintext .highlighter-rouge}               The minimum number of replicas that must acknowledge a write for the write to be considered successful.                                           `2`{.language-plaintext .highlighter-rouge}
  `uncleanLeaderElectionEnable`{.language-plaintext .highlighter-rouge}     Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss.   `false`{.language-plaintext .highlighter-rouge}
  `logFlushIntervalMessages`{.language-plaintext .highlighter-rouge}        The number of messages accumulated on a log partition before messages are flushed to disk                                                         `10000`{.language-plaintext .highlighter-rouge}
  `logFlushIntervalMs`{.language-plaintext .highlighter-rouge}              The maximum time in ms that a message in any topic is kept in memory before flushed to disk.                                                      `1000`{.language-plaintext .highlighter-rouge}
  `logRetentionBytes`{.language-plaintext .highlighter-rouge}               The maximum size of the log before deleting it.                                                                                                   `1073741824`{.language-plaintext .highlighter-rouge}
  `logRetentionCheckIntervalMs`{.language-plaintext .highlighter-rouge}     The frequency in milliseconds that the log cleaner checks whether any log is eligible for deletion.                                               `300000`{.language-plaintext .highlighter-rouge}
  `logRetentionHours`{.language-plaintext .highlighter-rouge}               The number of hours to eep a log file before deleting it (in hours).                                                                              `168`{.language-plaintext .highlighter-rouge}
  `logSegmentBytes`{.language-plaintext .highlighter-rouge}                 The maximum size of a single log file.                                                                                                            `1073741824`{.language-plaintext .highlighter-rouge}
  `messageMaxBytes`{.language-plaintext .highlighter-rouge}                 The largest record batch size allowed by Kafka (after compression if compression is enabled).                                                     `1048588`{.language-plaintext .highlighter-rouge}

More information can be found in the [Apache Kafka Documentation](https://kafka.apache.org/documentation/#brokerconfigs) and in the [Confluent Documentation](https://docs.confluent.io/platform/current/installation/configuration/broker-configs.html).

### Ports used by Kafka

For those still struggling with how the listeners work take a look at [Kafka Listeners - Explained](https://rmoff.net/2018/08/02/kafka-listeners-explained/) by [Robin Moffatt](https://twitter.com/rmoff/).

By default the [Headless Service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) will expose the pods in the port `9092`{.language-plaintext .highlighter-rouge}, `port.kafkaInternal`{.language-plaintext .highlighter-rouge}, and one can use this headless service as a Bootstrap Server.

We have setup the possibility for external access by changing the next values:

``` highlight
externalAccess:
  enabled: true
  initNodePort: 32400
## turn to support nodePort in docker desktop
isDocker: true
```

This will create a [nodeport service](https://kubernetes.io/docs/concepts/services-networking/service/#nodeport) that will expose each broker in a different port. So, if we have the `32400`{.language-plaintext .highlighter-rouge} as a start and we have `3`{.language-plaintext .highlighter-rouge} replicas we will have:

  pod                                                 map
  --------------------------------------------------- ----------------------------------------------------------
  `kafka-0`{.language-plaintext .highlighter-rouge}   `9094:32400/TCP`{.language-plaintext .highlighter-rouge}
  `kafka-1`{.language-plaintext .highlighter-rouge}   `9094:32401/TCP`{.language-plaintext .highlighter-rouge}
  `kafka-2`{.language-plaintext .highlighter-rouge}   `9094:32403/TCP`{.language-plaintext .highlighter-rouge}

### Kerberos Authentication

This chart is prepared to enable [Kerberos authentication in Kafka](https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_gssapi.html#brokers)

  Parameter                                                                 Description                                                                                                                                                                                                                                                                       Default
  ------------------------------------------------------------------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ----------------------------------------------------
  `kerberos.enabled`{.language-plaintext .highlighter-rouge}                Boolean to control if Kerberos is enabled.                                                                                                                                                                                                                                        `false`{.language-plaintext .highlighter-rouge}
  `kerberos.krb5Conf`{.language-plaintext .highlighter-rouge}               Name of the [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) that stores the `krb5.conf`{.language-plaintext .highlighter-rouge}, Kerberos [Configuration file](https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html)              `nil`{.language-plaintext .highlighter-rouge}**ยน**
  `kerberos.keyTabSecret`{.language-plaintext .highlighter-rouge}           Name of the [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) that stores the [Keytab](https://web.mit.edu/kerberos/krb5-1.19/doc/basic/keytab_def.html)                                                                                                        `nil`{.language-plaintext .highlighter-rouge}**ยน**
  `kerberos.jaasConf`{.language-plaintext .highlighter-rouge}               Name of the [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) that stores the JAAS configuration files per host.                                                                                                                                          `nil`{.language-plaintext .highlighter-rouge}**ยน**
  `kerberos.testUserKeytabSecret`{.language-plaintext .highlighter-rouge}   Name of the [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) that stores the [Keytab](https://web.mit.edu/kerberos/krb5-1.19/doc/basic/keytab_def.html) for the test user. Mandatory when `kerberos.testUser`{.language-plaintext .highlighter-rouge} is set   `nil`{.language-plaintext .highlighter-rouge}

> **ยน** When `kerberos.enabled`{.language-plaintext .highlighter-rouge} these parameters are required, and the [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) and [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) need to exist beforehand.

### Authorization Using ACLs

This chart is prepared to enable [Authorization using ACLs in Kafka](https://docs.confluent.io/platform/current/kafka/authorization.html) but doesn't manage ACLs.

> To enable ACLs, an authentication mechanism must also be enabled, e.g. Kerberos.

  Parameter                                                Description                              Default
  -------------------------------------------------------- ---------------------------------------- -------------------------------------------------
  `acls.enabled`{.language-plaintext .highlighter-rouge}   Boolean to control if ACLs are enabled   `false`{.language-plaintext .highlighter-rouge}

### Data Persistence

The Kafka Kafka Data directory can be tweaked with:

  Parameter                                                     Description                                                                                                                           Default
  ------------------------------------------------------------- ------------------------------------------------------------------------------------------------------------------------------------- ------------------------------------------------
  `data.storageClass`{.language-plaintext .highlighter-rouge}   Valid options: `nil`{.language-plaintext .highlighter-rouge}, `"-"`{.language-plaintext .highlighter-rouge}, or storage class name.   `nil`{.language-plaintext .highlighter-rouge}
  `data.storageSize`{.language-plaintext .highlighter-rouge}    Size for data dir.                                                                                                                    `10Gi`{.language-plaintext .highlighter-rouge}

This will allow the creation of a [Persistent Volume](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) using a specific [Storage Class](https://kubernetes.io/docs/concepts/storage/storage-classes/). However, [Access Mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes).

### Resources for Containers

Regarding the management of [Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) the next defaults regarding requests and limits are set:

With this in mind the next defaults regarding resources and limits are set:

  Parameter                                                             Description                                                               Default
  --------------------------------------------------------------------- ------------------------------------------------------------------------- --------------------------------------------------
  `resources.limits.cpu`{.language-plaintext .highlighter-rouge}        a container cannot use more CPU than the configured limit                 `1`{.language-plaintext .highlighter-rouge}
  `resources.limits.memory`{.language-plaintext .highlighter-rouge}     a container cannot use more Memory than the configured limit              `1400Mi`{.language-plaintext .highlighter-rouge}
  `resources.requests.cpu`{.language-plaintext .highlighter-rouge}      a container is guaranteed to be allocated as much CPU as it requests      `250m`{.language-plaintext .highlighter-rouge}
  `resources.requests.memory`{.language-plaintext .highlighter-rouge}   a container is guaranteed to be allocated as much Memory as it requests   `512Mi`{.language-plaintext .highlighter-rouge}

In terms of the JVM the next default is set:

  Parameter                                            Description                              Default
  ---------------------------------------------------- ---------------------------------------- -----------------------------------------------------------------------------------------------------
  `heapOpts`{.language-plaintext .highlighter-rouge}   The JVM Heap Options for Kafka Broker.   `"-XX:MaxRAMPercentage=75.0 -XX:InitialRAMPercentage=50.0"`{.language-plaintext .highlighter-rouge}

### Advance Configuration

Check the `values.yaml`{.language-plaintext .highlighter-rouge} for more advance configuration such as:

-   [Liveness and Readiness Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes)
-   [Pod Security Context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod)
-   [Container Security Context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)

This site is open source. [Improve this page](https://github.com/ricardo-aires/helm-charts/edit/main/charts/kafka/README.md).
