# Fix common cluster issues | Elasticsearch Guide [7.14] | Elastic (www.elastic.co)

<https://www.elastic.co/guide/en/elasticsearch/reference/7.14/fix-common-cluster-issues.html#circuit-breaker-errors>

## Content

::: iframe
:::

**IMPORTANT**: No additional bug fixes or documentation updates
will be released for this version. For the latest information, see the
[current release documentation](../current/index.html).

[Elastic Docs](/guide/)
›[Elasticsearch Guide \[7.14\]](index.html)
›[How to](how-to.html)

[« Tune for disk usage](tune-for-disk-usage.html)
[Size your shards »](size-your-shards.html)

## []{#fix-common-cluster-issues}Fix common cluster issues[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"} {#fix-common-cluster-issuesedit .title}

This guide describes how to fix common problems with Elasticsearch clusters.

### []{#circuit-breaker-errors}Circuit breaker errors[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

Elasticsearch uses [circuit breakers](circuit-breaker.html "Circuit breaker settings"){.xref} to prevent nodes from running out
of JVM heap memory. If Elasticsearch estimates an operation would exceed a
circuit breaker, it stops the operation and returns an error.

By default, the [parent circuit breaker](circuit-breaker.html#parent-circuit-breaker "Parent circuit breaker"){.xref} triggers at
95% JVM memory usage. To prevent errors, we recommend taking steps to reduce
memory pressure if usage consistently exceeds 85%.

#### []{#diagnose-circuit-breaker-errors}Diagnose circuit breaker errors[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Error messages**

If a request triggers a circuit breaker, Elasticsearch returns an error with a `429`{.literal} HTTP
status code.

``` {.programlisting .prettyprint .lang-js}
{
  'error': {
    'type': 'circuit_breaking_exception',
    'reason': '[parent] Data too large, data for [<http_request>] would be [123848638/118.1mb], which is larger than the limit of [123273216/117.5mb], real usage: [120182112/114.6mb], new bytes reserved: [3666526/3.4mb]',
    'bytes_wanted': 123848638,
    'bytes_limit': 123273216,
    'durability': 'TRANSIENT'
  },
  'status': 429
}
```

Elasticsearch also writes circuit breaker errors to [`elasticsearch.log`{.literal}](logging.html "Logging"){.xref}. This
is helpful when automated processes, such as allocation, trigger a circuit
breaker.

``` {.programlisting .prettyprint .lang-txt}
Caused by: org.elasticsearch.common.breaker.CircuitBreakingException: [parent] Data too large, data for [<transport_request>] would be [num/numGB], which is larger than the limit of [num/numGB], usages [request=0/0b, fielddata=num/numKB, in_flight_requests=num/numGB, accounting=num/numGB]
```

**Check JVM memory usage**

If you've enabled Stack Monitoring, you can view JVM memory usage in Kibana. In
the main menu, click **Stack Monitoring**. On the Stack Monitoring **Overview**
page, click **Nodes**. The **JVM Heap** column lists the current memory usage
for each node.

You can also use the [cat nodes API](cat-nodes.html "cat nodes API"){.xref} to get the current
`heap.percent`{.literal} for each node.

``` {.programlisting .prettyprint .lang-console}
GET _cat/nodes?v=true&h=name,node*,heap*
```

To get the JVM memory usage for each circuit breaker, use the
[node stats API](cluster-nodes-stats.html "Nodes stats API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _nodes/stats/breaker
```

#### []{#prevent-circuit-breaker-errors}Prevent circuit breaker errors[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Reduce JVM memory pressure**

High JVM memory pressure often causes circuit breaker errors. See
[High JVM memory pressure](fix-common-cluster-issues.html#high-jvm-memory-pressure "High JVM memory pressure"){.xref}.

**Avoid using fielddata on `text`{.literal} fields**

For high-cardinality `text`{.literal} fields, fielddata can use a large amount of JVM
memory. To avoid this, Elasticsearch disables fielddata on `text`{.literal} fields by default. If
you've enabled fielddata and triggered the [fielddata
circuit breaker](circuit-breaker.html#fielddata-circuit-breaker "Field data circuit breaker"){.xref}, consider disabling it and using a `keyword`{.literal} field instead.
See [`fielddata`{.literal} mapping parameter](fielddata.html "fielddata mapping parameter"){.xref}.

**Clear the fieldata cache**

If you've triggered the fielddata circuit breaker and can't disable fielddata,
use the [clear cache API](indices-clearcache.html "Clear cache API"){.xref} to clear the fielddata cache.
This may disrupt any in-flight searches that use fielddata.

``` {.programlisting .prettyprint .lang-console}
POST _cache/clear?fielddata=true
```

### []{#high-cpu-usage}High CPU usage[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

Elasticsearch uses [thread pools](modules-threadpool.html "Thread pools"){.xref} to manage CPU resources for
concurrent operations. High CPU usage typically means one or more thread pools
are running low.

If a thread pool is depleted, Elasticsearch will [reject requests](fix-common-cluster-issues.html#rejected-requests "Rejected requests"){.xref}
related to the thread pool. For example, if the `search`{.literal} thread pool is
depleted, Elasticsearch will reject search requests until more threads are available.

#### []{#diagnose-high-cpu-usage}Diagnose high CPU usage[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Check CPU usage**

Elasticsearch Service

Self-managed

From your deployment menu, click **Performance**. The page's **CPU Usage** chart
shows your deployment's CPU usage as a percentage.

High CPU usage can also deplete your CPU credits. CPU credits let Elasticsearch Service provide
smaller clusters with a performance boost when needed. The **CPU credits**
chart shows your remaining CPU credits, measured in seconds of CPU time.

You can also use the [cat nodes API](cat-nodes.html "cat nodes API"){.xref} to get the current CPU usage
for each node.

``` {.programlisting .prettyprint .lang-console}
GET _cat/nodes?v=true&s=cpu:desc
```

The response's `cpu`{.literal} column contains the current CPU usage as a percentage. The
`node`{.literal} column contains the node's name.

Use the [cat nodes API](cat-nodes.html "cat nodes API"){.xref} to get the current CPU usage for each node.

``` {.programlisting .prettyprint .lang-console}
GET _cat/nodes?v=true&s=cpu:desc
```

The response's `cpu`{.literal} column contains the current CPU usage as a percentage. The
`node`{.literal} column contains the node's name.

**Check hot threads**

If a node has high CPU usage, use the [nodes hot
threads API](cluster-nodes-hot-threads.html "Nodes hot threads API"){.xref} to check for resource-intensive threads running on the node.

``` {.programlisting .prettyprint .lang-console}
GET _nodes/my-node,my-other-node/hot_threads
```

This API returns a breakdown of any hot threads in plain text.

#### []{#reduce-cpu-usage}Reduce CPU usage[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

The following tips outline the most common causes of high CPU usage and their
solutions.

**Scale your cluster**

Heavy indexing and search loads can deplete smaller thread pools. To better
handle heavy workloads, add more nodes to your cluster or upgrade your existing
nodes to increase capacity.

**Spread out bulk requests**

While more efficient than individual requests, large [bulk indexing](docs-bulk.html "Bulk API"){.xref}
or [multi-search](search-multi-search.html "Multi search API"){.xref} requests still require CPU resources. If
possible, submit smaller requests and allow more time between them.

**Cancel long-running searches**

Long-running searches can block threads in the `search`{.literal} thread pool. To check
for these searches, use the [task management API](tasks.html "Task management API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _tasks?actions=*search&detailed
```

The response's `description`{.literal} contains the search request and its queries.
`running_time_in_nanos`{.literal} shows how long the search has been running.

``` {.programlisting .prettyprint .lang-console-result}
{
  "nodes" : {
    "oTUltX4IQMOUUVeiohTt8A" : {
      "name" : "my-node",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "tasks" : {
        "oTUltX4IQMOUUVeiohTt8A:464" : {
          "node" : "oTUltX4IQMOUUVeiohTt8A",
          "id" : 464,
          "type" : "transport",
          "action" : "indices:data/read/search",
          "description" : "indices[my-index], search_type[QUERY_THEN_FETCH], source[{\"query\":...}]",
          "start_time_in_millis" : 4081771730000,
          "running_time_in_nanos" : 13991383,
          "cancellable" : true
        }
      }
    }
  }
}
```

To cancel a search and free up resources, use the API's `_cancel`{.literal} endpoint.

``` {.programlisting .prettyprint .lang-console}
POST _tasks/oTUltX4IQMOUUVeiohTt8A:464/_cancel
```

For additional tips on how to track and avoid resource-intensive searches, see
[Avoid expensive searches](fix-common-cluster-issues.html#avoid-expensive-searches){.xref}.

### []{#high-jvm-memory-pressure}High JVM memory pressure[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

High JVM memory usage can degrade cluster performance and trigger
[circuit breaker errors](fix-common-cluster-issues.html#circuit-breaker-errors "Circuit breaker errors"){.xref}. To prevent this, we recommend
taking steps to reduce memory pressure if a node's JVM memory usage consistently
exceeds 85%.

#### []{#diagnose-high-jvm-memory-pressure}Diagnose high JVM memory pressure[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Check JVM memory pressure**

Elasticsearch Service

Self-managed

From your deployment menu, click **Elasticsearch**. Under **Instances**, each
instance displays a **JVM memory pressure** indicator. When the JVM memory
pressure reaches 75%, the indicator turns red.

You can also use the [nodes stats API](cluster-nodes-stats.html "Nodes stats API"){.xref} to calculate the
current JVM memory pressure for each node.

``` {.programlisting .prettyprint .lang-console}
GET _nodes/stats?filter_path=nodes.*.jvm.mem.pools.old
```

Use the response to calculate memory pressure as follows:

JVM Memory Pressure = `used_in_bytes`{.literal} / `max_in_bytes`{.literal}

To calculate the current JVM memory pressure for each node, use the
[nodes stats API](cluster-nodes-stats.html "Nodes stats API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _nodes/stats?filter_path=nodes.*.jvm.mem.pools.old
```

Use the response to calculate memory pressure as follows:

JVM Memory Pressure = `used_in_bytes`{.literal} / `max_in_bytes`{.literal}

**Check garbage collection logs**

As memory usage increases, garbage collection becomes more frequent and takes
longer. You can track the frequency and length of garbage collection events in
[`elasticsearch.log`{.literal}](logging.html "Logging"){.xref}. For example, the following event states Elasticsearch
spent more than 50% (21 seconds) of the last 40 seconds performing garbage
collection.

``` {.programlisting .prettyprint .lang-log}
[timestamp_short_interval_from_last][INFO ][o.e.m.j.JvmGcMonitorService] [node_id] [gc][number] overhead, spent [21s] collecting in the last [40s]
```

#### []{#reduce-jvm-memory-pressure}Reduce JVM memory pressure[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Reduce your shard count**

Every shard uses memory. In most cases, a small set of large shards uses fewer
resources than many small shards. For tips on reducing your shard count, see
[*Size your shards*](size-your-shards.html "Size your shards"){.xref}.

[]{#avoid-expensive-searches}**Avoid expensive searches**

Expensive searches can use large amounts of memory. To better track expensive
searches on your cluster, enable [slow logs](index-modules-slowlog.html "Slow Log"){.xref}.

Expensive searches may have a large [`size`{.literal} argument](paginate-search-results.html "Paginate search results"){.xref},
use aggregations with a large number of buckets, or include
[expensive queries](query-dsl.html#query-dsl-allow-expensive-queries){.xref}. To prevent expensive
searches, consider the following setting changes:

-   Lower the `size`{.literal} limit using the
    [`index.max_result_window`{.literal}](index-modules.html#index-max-result-window){.xref} index setting.
-   Decrease the maximum number of allowed aggregation buckets using the
    [search.max_buckets](search-settings.html#search-settings-max-buckets){.xref} cluster setting.
-   Disable expensive queries using the
    [`search.allow_expensive_queries`{.literal}](query-dsl.html#query-dsl-allow-expensive-queries){.xref} cluster
    setting.

``` {.programlisting .prettyprint .lang-console}
PUT _settings
{
  "index.max_result_window": 5000
}

PUT _cluster/settings
{
  "persistent": {
    "search.max_buckets": 20000,
    "search.allow_expensive_queries": false
  }
}
```

**Prevent mapping explosions**

Defining too many fields or nesting fields too deeply can lead to
[mapping explosions](mapping.html#mapping-limit-settings "Settings to prevent mapping explosion"){.xref} that use large amounts of memory.
To prevent mapping explosions, use the [mapping limit
settings](mapping-settings-limit.html "Mapping limit settings"){.xref} to limit the number of field mappings.

**Spread out bulk requests**

While more efficient than individual requests, large [bulk indexing](docs-bulk.html "Bulk API"){.xref}
or [multi-search](search-multi-search.html "Multi search API"){.xref} requests can still create high JVM
memory pressure. If possible, submit smaller requests and allow more time
between them.

**Upgrade node memory**

Heavy indexing and search loads can cause high JVM memory pressure. To better
handle heavy workloads, upgrade your nodes to increase their memory capacity.

### []{#red-yellow-cluster-status}Red or yellow cluster status[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

A red or yellow cluster status indicates one or more shards are missing or
unallocated. These unassigned shards increase your risk of data loss and can
degrade cluster performance.

#### []{#diagnose-cluster-status}Diagnose your cluster status[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Check your cluster status**

Use the [cluster health API](cluster-health.html "Cluster health API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _cluster/health?filter_path=status,*_shards
```

A healthy cluster has a green `status`{.literal} and zero `unassigned_shards`{.literal}. A yellow
status means only replicas are unassigned. A red status means one or
more primary shards are unassigned.

**View unassigned shards**

To view unassigned shards, use the [cat shards API](cat-shards.html "cat shards API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _cat/shards?v=true&h=index,shard,prirep,state,node,unassigned.reason&s=state
```

Unassigned shards have a `state`{.literal} of `UNASSIGNED`{.literal}. The `prirep`{.literal} value is `p`{.literal} for
primary shards and `r`{.literal} for replicas. The `unassigned.reason`{.literal} describes why the
shard remains unassigned.

To get a more in-depth explanation of an unassigned shard's allocation status,
use the [cluster allocation explanation API](cluster-allocation-explain.html "Cluster allocation explain API"){.xref}. You
can often use details in the response to resolve the issue.

``` {.programlisting .prettyprint .lang-console}
GET _cluster/allocation/explain?filter_path=index,node_allocation_decisions.node_name,node_allocation_decisions.deciders.*
{
  "index": "my-index",
  "shard": 0,
  "primary": false,
  "current_node": "my-node"
}
```

#### []{#fix-red-yellow-cluster-status}Fix a red or yellow cluster status[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

A shard can become unassigned for several reasons. The following tips outline the
most common causes and their solutions.

**Re-enable shard allocation**

You typically disable allocation during a [restart](restart-cluster.html "Full-cluster restart and rolling restart"){.xref} or other
cluster maintenance. If you forgot to re-enable allocation afterward, Elasticsearch will
be unable to assign shards. To re-enable allocation, reset the
`cluster.routing.allocation.enable`{.literal} cluster setting.

``` {.programlisting .prettyprint .lang-console}
PUT _cluster/settings
{
  "persistent" : {
    "cluster.routing.allocation.enable" : null
  }
}
```

**Recover lost nodes**

Shards often become unassigned when a data node leaves the cluster. This can
occur for several reasons, ranging from connectivity issues to hardware failure.
After you resolve the issue and recover the node, it will rejoin the cluster.
Elasticsearch will then automatically allocate any unassigned shards.

To avoid wasting resources on temporary issues, Elasticsearch [delays
allocation](delayed-allocation.html "Delaying allocation when a node leaves"){.xref} by one minute by default. If you've recovered a node and don't want
to wait for the delay period, you can call the [cluster reroute
API](cluster-reroute.html "Cluster reroute API"){.xref} with no arguments to start the allocation process. The process runs
asynchronously in the background.

``` {.programlisting .prettyprint .lang-console}
POST _cluster/reroute
```

**Fix allocation settings**

Misconfigured allocation settings can result in an unassigned primary shard.
These settings include:

-   [Shard allocation](shard-allocation-filtering.html "Index-level shard allocation filtering"){.xref} index settings
-   [Allocation filtering](modules-cluster.html#cluster-shard-allocation-filtering "Cluster-level shard allocation filtering"){.xref} cluster settings
-   [Allocation awareness](modules-cluster.html#shard-allocation-awareness "Shard allocation awareness"){.xref} cluster settings

To review your allocation settings, use the [get index
settings](indices-get-settings.html "Get index settings API"){.xref} and [get cluster settings](cluster-get-settings.html "Cluster get settings API"){.xref} APIs.

``` {.programlisting .prettyprint .lang-console}
GET my-index/_settings?flat_settings=true&include_defaults=true

GET _cluster/settings?flat_settings=true&include_defaults=true
```

You can change the settings using the [update index
settings](indices-update-settings.html "Update index settings API"){.xref} and [update cluster settings](cluster-update-settings.html "Cluster update settings API"){.xref} APIs.

**Allocate or reduce replicas**

To protect against hardware failure, Elasticsearch will not assign a replica to the same
node as its primary shard. If no other data nodes are available to host the
replica, it remains unassigned. To fix this, you can:

-   Add a data node to the same tier to host the replica.
-   Change the `index.number_of_replicas`{.literal} index setting to reduce the number of
    replicas for each primary shard. We recommend keeping at least one replica per
    primary.

``` {.programlisting .prettyprint .lang-console}
PUT _settings
{
  "index.number_of_replicas": 1
}
```

**Free up or increase disk space**

Elasticsearch uses a [low disk watermark](modules-cluster.html#disk-based-shard-allocation "Disk-based shard allocation settings"){.xref} to ensure data
nodes have enough disk space for incoming shards. By default, Elasticsearch does not
allocate shards to nodes using more than 85% of disk space.

To check the current disk space of your nodes, use the [cat
allocation API](cat-allocation.html "cat allocation API"){.xref}.

``` {.programlisting .prettyprint .lang-console}
GET _cat/allocation?v=true&h=node,shards,disk.*
```

If your nodes are running low on disk space, you have a few options:

-   Upgrade your nodes to increase disk space.

-   Delete unneeded indices to free up space. If you use ILM, you can
    update your lifecycle policy to use [searchable
    snapshots](ilm-searchable-snapshot.html "Searchable snapshot"){.xref} or add a delete phase. If you no longer need to search the data, you
    can use a [snapshot](snapshot-restore.html "Snapshot and restore"){.xref} to store it off-cluster.

-   If you no longer write to an index, use the [force merge
    API](indices-forcemerge.html "Force merge API"){.xref} or ILM's [force merge action](ilm-forcemerge.html "Force merge"){.xref} to merge its
    segments into larger ones.

    ``` {.programlisting .prettyprint .lang-console}
    POST my-index/_forcemerge
    ```

-   If an index is read-only, use the [shrink index API](indices-shrink-index.html "Shrink index API"){.xref} or
    ILM's [shrink action](ilm-shrink.html "Shrink"){.xref} to reduce its primary shard count.

    ``` {.programlisting .prettyprint .lang-console}
    POST my-index/_shrink/my-shrunken-index
    ```

-   If your node has a large disk capacity, you can increase the low disk
    watermark or set it to an explicit byte value.

    ``` {.programlisting .prettyprint .lang-console}
    PUT _cluster/settings
    {
      "persistent": {
        "cluster.routing.allocation.disk.watermark.low": "30gb"
      }
    }
    ```

**Reduce JVM memory pressure**

Shard allocation requires JVM heap memory. High JVM memory pressure can trigger
[circuit breakers](circuit-breaker.html "Circuit breaker settings"){.xref} that stop allocation and leave shards
unassigned. See [High JVM memory pressure](fix-common-cluster-issues.html#high-jvm-memory-pressure "High JVM memory pressure"){.xref}.

**Recover data for a lost primary shard**

If a node containing a primary shard is lost, Elasticsearch can typically replace it
using a replica on another node. If you can't recover the node and replicas
don't exist or are irrecoverable, you'll need to re-add the missing data from a
[snapshot](snapshot-restore.html "Snapshot and restore"){.xref} or the original data source.

Only use this option if node recovery is no longer possible. This
process allocates an empty primary shard. If the node later rejoins the cluster,
Elasticsearch will overwrite its primary shard with data from this newer empty shard,
resulting in data loss.

Use the [cluster reroute API](cluster-reroute.html "Cluster reroute API"){.xref} to manually allocate the
unassigned primary shard to another data node in the same tier. Set
`accept_data_loss`{.literal} to `true`{.literal}.

``` {.programlisting .prettyprint .lang-console}
POST _cluster/reroute
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "my-index",
        "shard": 0,
        "node": "my-node",
        "accept_data_loss": "true"
      }
    }
  ]
}
```

If you backed up the missing index data to a snapshot, use the
[restore snapshot API](restore-snapshot-api.html "Restore snapshot API"){.xref} to restore the individual index.
Alternatively, you can index the missing data from the original data source.

### []{#rejected-requests}Rejected requests[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

When Elasticsearch rejects a request, it stops the operation and returns an error with a
`429`{.literal} response code. Rejected requests are commonly caused by:

-   A [depleted thread pool](fix-common-cluster-issues.html#high-cpu-usage "High CPU usage"){.xref}. A depleted `search`{.literal} or `write`{.literal}
    thread pool returns a `TOO_MANY_REQUESTS`{.literal} error message.
-   A [circuit breaker error](fix-common-cluster-issues.html#circuit-breaker-errors "Circuit breaker errors"){.xref}.
-   High [indexing pressure](index-modules-indexing-pressure.html "Indexing pressure"){.xref} that exceeds the
    [`indexing_pressure.memory.limit`{.literal}](index-modules-indexing-pressure.html#memory-limits "Memory limits"){.xref}.

#### []{#check-rejected-tasks}Check rejected tasks[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

To check the number of rejected tasks for each thread pool, use the
[cat thread pool API](cat-thread-pool.html "cat thread pool API"){.xref}. A high ratio of `rejected`{.literal} to
`completed`{.literal} tasks, particularly in the `search`{.literal} and `write`{.literal} thread pools, means
Elasticsearch regularly rejects requests.

``` {.programlisting .prettyprint .lang-console}
GET /_cat/thread_pool?v=true&h=id,name,active,rejected,completed
```

#### []{#prevent-rejected-requests}Prevent rejected requests[edit](https://github.com/elastic/elasticsearch/edit/7.14/docs/reference/how-to/fix-common-cluster-issues.asciidoc "Editing on GitHub is available to Elastic"){.edit_me .edit_me_private rel="nofollow"}

**Fix high CPU and memory usage**

If Elasticsearch regularly rejects requests and other tasks, your cluster likely has high
CPU usage or high JVM memory pressure. For tips, see [High CPU usage](fix-common-cluster-issues.html#high-cpu-usage "High CPU usage"){.xref} and
[High JVM memory pressure](fix-common-cluster-issues.html#high-jvm-memory-pressure "High JVM memory pressure"){.xref}.

**Prevent circuit breaker errors**

If you regularly trigger circuit breaker errors, see [Circuit breaker errors](fix-common-cluster-issues.html#circuit-breaker-errors "Circuit breaker errors"){.xref}
for tips on diagnosing and preventing them.

[« Tune for disk usage](tune-for-disk-usage.html)
[Size your shards »](size-your-shards.html)

Most Popular

Video

[](https://www.elastic.co/webinars/getting-started-elasticsearch?page=docs&placement=top-video)

Get Started with Elasticsearch

Video

[](https://www.elastic.co/webinars/getting-started-kibana?page=docs&placement=top-video)

Intro to Kibana

Video

[](https://www.elastic.co/webinars/introduction-elk-stack?page=docs&placement=top-video)

ELK for Logs & Metrics
